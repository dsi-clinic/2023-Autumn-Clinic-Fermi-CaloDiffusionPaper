{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Padding Analysis of Downsampling & Upsampling",
   "id": "3611870c4720cb51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Imports so notebook looks nice\n",
    "\"\"\"\n",
    "\n",
    "from einops import rearrange\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from inspect import isfunction\n",
    "from functools import partial"
   ],
   "id": "121a1a5ee5fc494d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Downsampling utilizes `CylindricalConv`, while Upsampling uses `CylindricalConvTrans`. Our tensor is formatted as `(batch_size, channels, z_bin, phi_bin, r_bin)`, and both convolutions utilize the `torch.nn` convolution functions to actually manipulate tensor size. However, artificial padding is added beforehand in the phi_bin dimension in order to mimic a cylindrical shape. The equation given in the comments for each convolution doesn't seem to be correct. The goal of this analysis is to see if we can modify this artificial padding so that when we stride (compress) by a factor that isn't 2, the code doesn't error as the artificial padding is currently hard coded for this stride.",
   "id": "9ff4a950f9fc7fcd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Downsampling & CylindricalConv",
   "id": "e372e6eb840093e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Downsampling code snippet:\n",
    "\n",
    "compress_Z = True usually, compress = 2 by default\n",
    "\"\"\"\n",
    "# Z_stride = compress if compress_Z else 1\n",
    "# if cylindrical:\n",
    "#     return CylindricalConv(\n",
    "#         dim,\n",
    "#         dim,\n",
    "#         kernel_size=(3, 4, 4),\n",
    "#         stride=(Z_stride, compress, compress),\n",
    "#         padding=1,\n",
    "#     )"
   ],
   "id": "70f4d2864eebacdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CylindricalConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Cylindrical 3D Convolution layer.\n",
    "\n",
    "    Assumes input tensor format: (batch_size, channels, z_bin, phi_bin, r_bin)\n",
    "    \n",
    "    All tensor size changes related to padding & stride only affect z_bin, phi_bin, r_bin.\n",
    "    Padding and stride are all lists of length 3, with each index corresponding to the respective\n",
    "    bin above.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, dim_in, dim_out, kernel_size=3, stride=1, groups=1, padding=0, bias=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Adjust padding for circular dimension\n",
    "        \n",
    "        # Makes padding [1, 1, 1]\n",
    "        \n",
    "        if isinstance(padding, int):\n",
    "            padding = [padding] * 3\n",
    "        else:\n",
    "            self.padding_orig = copy.copy(padding)\n",
    "            padding = list(padding)\n",
    "            padding[1] = 0  # No padding for phi_bin dimension; will pad manually\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding_orig = copy.copy(padding)\n",
    "        padding[1] = 0  # Remove padding for phi_bin dimension\n",
    "        \n",
    "        # padding = [1, 0, 1] for nn.Conv3d\n",
    "        \n",
    "        self.conv = nn.Conv3d(\n",
    "            dim_in,\n",
    "            dim_out,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            groups=groups,\n",
    "            padding=padding,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the cylindrical convolution.\n",
    "\n",
    "        Pads the phi_bin dimension circularly before applying convolution.\n",
    "        \"\"\"\n",
    "        # Circular padding for the phi_bin dimension\n",
    "        # To achieve 'same' use padding P = ((S-1)*W-S+F)/2, with F = filter size, S = stride, W = input size\n",
    "        # Pad last dim with nothing, 2nd to last dim is circular one\n",
    "        \n",
    "        # padding_orig = [1, 1, 1]\n",
    "        \n",
    "        circ_pad = self.padding_orig[1]\n",
    "        x = F.pad(x, pad=(0, 0, circ_pad, circ_pad, 0, 0), mode=\"circular\")\n",
    "        \n",
    "        # x tensor size is now (batch_size, channels, z_bin, phi_bin + 2, r_bin)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        \n",
    "        # x tensor size is actually downsampled in nn.Conv3d call\n",
    "        return x"
   ],
   "id": "21094fff49a371a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[nn.Conv3d](https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html):\n",
    "Shrinks tensor (z, phi r) with dimension index $i$ from $d_{\\text{i_in}}$ to $d_{\\text{i_out}}$ following:\n",
    "$$\n",
    "d_{\\text{i_out}} = \\frac{d_{\\text{i_in}} + 2 \\times \\text{padding}_i - \\text{dilation}_i \\times (\\text{kernel_size}_i -1) - 1}{\\text{stride}_i} + 1\n",
    "$$"
   ],
   "id": "d45250d7836da0c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this case, $\\text{dilation}_i = 1$ so we can simplify the equation to:\n",
    "$$\n",
    "d_{\\text{i_out}} = \\frac{d_{\\text{i_in}} + 2 \\times \\text{padding}_i - \\text{kernel_size}_i}{\\text{stride}_i} + 1\n",
    "$$\n"
   ],
   "id": "cd14c5e18b525284"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We know `padding = [1, 0, 1]` and `kernel_size = (3, 4, 4)`. Looking at the phi_bin dimension (index 1), $\\text{padding}_i = 0$ and $\\text{kernel_size}_i = 4$. For equation simplicity, let $\\text{kernel_size}_i = k$ and $\\text{stride} = s$. Let $d_{\\text{i_in}} = \\text{phi_bin} + \\text{circ_pad} \\times 2$, or more simply $d_i + p \\times 2$. Ideally as well, $d_{\\text{i_out}} = d_i / s$.",
   "id": "9b2c72a89f51bf5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Thus, our equation is now:\n",
    "$$\n",
    "\\frac{d_i}{s} = \\frac{d_i + p \\times 2 - k}{s} + 1\n",
    "$$\n",
    "\n",
    "Example: initial phi_bin dimension is 10 with artificial padding 1 and stride 2:\n",
    "$$\n",
    "\\frac{10}{2} = \\frac{10 + 2 - 4}{2} + 1\n",
    "$$\n",
    "$$\n",
    "5 = 5\n",
    "$$"
   ],
   "id": "5fab5a20808a0fc6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To obtain a variational value for $\\text{circ_pad} = p$ to appropriately modify our tensor for a variational stride $s$, we solve for $p$:\n",
    "$$\n",
    "d_i = d_i + p \\times 2 - k + s\n",
    "$$\n",
    "$$\n",
    "p = \\frac{k - s}{2}\n",
    "$$"
   ],
   "id": "462f0fdd65dc1982"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is our ideal value for the artificial padding of the phi dimension if we were to use a stride != 2. However, this raises issues for instance, in a stride of 1, where padding becomes 1.5. Only integers are allowed for the `functional.pad` function. Knowing kernel size is hard coded to 4 restricts our options a LOT, and also opens the question if we should be modifying more than just the artificial padding if we want to implement variational stride.",
   "id": "b17e1ec78ce9a7ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Upsampling & CylindriclConvTrans",
   "id": "4097f9af3a4d91b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Upsampling code snippet:\n",
    "\n",
    "compress_Z = True usually, compress = 2 by default\n",
    "\n",
    "For simplicity sake, consider extra_upsample = 0 so no output_padding\n",
    "\"\"\"\n",
    "# Z_stride = compress if compress_Z else 1\n",
    "# Z_kernel = 4 if extra_upsample[0] > 0 else 3\n",
    "# \n",
    "# extra_upsample[0] = 0  # Ensure Z-dimension extra upsample is zero\n",
    "# if cylindrical:\n",
    "#     return CylindricalConvTrans(\n",
    "#         dim,\n",
    "#         dim,\n",
    "#         kernel_size=(Z_kernel, 4, 4),\n",
    "#         stride=(Z_stride, compress, compress),\n",
    "#         padding=1,\n",
    "#         output_padding=extra_upsample,\n",
    "#     )"
   ],
   "id": "60023f7bfa459456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CylindricalConvTrans(nn.Module):\n",
    "    \"\"\"\n",
    "    Cylindrical 3D Transposed Convolution layer.\n",
    "\n",
    "    Assumes input tensor format: (batch_size, channels, z_bin, phi_bin, r_bin)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim_in,\n",
    "            dim_out,\n",
    "            kernel_size=(3, 4, 4),\n",
    "            stride=(1, 2, 2),\n",
    "            groups=1,\n",
    "            padding=1,\n",
    "            output_padding=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Adjust padding for circular dimension\n",
    "\n",
    "        # Makes padding [1, 1, 1]\n",
    "        \n",
    "        if not isinstance(padding, int):\n",
    "            self.padding_orig = copy.copy(padding)\n",
    "            padding = list(padding)\n",
    "        else:\n",
    "            padding = [padding] * 3\n",
    "            self.padding_orig = copy.copy(padding)\n",
    "\n",
    "        padding[1] = kernel_size[1] - 1  # Adjust padding for phi_bin dimension\n",
    "\n",
    "        # padding = [1, 3, 1] for nn.ConvTranspose3d\n",
    "        \n",
    "        self.convTrans = nn.ConvTranspose3d(\n",
    "            dim_in,\n",
    "            dim_out,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            output_padding=output_padding,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the cylindrical transposed convolution.\n",
    "\n",
    "        Pads the phi_bin dimension circularly before applying convolution.\n",
    "        \"\"\"\n",
    "        # Circular padding for the phi_bin dimension\n",
    "        # Out size is : O = (i-1)*S + K - 2P\n",
    "        # To achieve 'same' use padding P = ((S-1)*W-S+F)/2, with F = filter size, S = stride, W = input size\n",
    "        # Pad last dim with nothing, 2nd to last dim is circular one\n",
    "        \n",
    "        # padding_orig = [1, 1, 1]\n",
    "\n",
    "        circ_pad = self.padding_orig[1]\n",
    "        x = F.pad(x, pad=(0, 0, circ_pad, circ_pad, 0, 0), mode=\"circular\")\n",
    "\n",
    "        # x tensor size is now (batch_size, channels, z_bin, phi_bin + 2, r_bin)\n",
    "\n",
    "        x = self.convTrans(x)\n",
    "\n",
    "        # x tensor size is actually upsampled in nn.ConvTranspose3d call\n",
    "        return x"
   ],
   "id": "e675c744b3e2a030"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[nn.ConvTranspose3d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html):\n",
    "Increases tensor (z, phi r) with dimension index $i$ from $d_{\\text{i_in}}$ to $d_{\\text{i_out}}$ following:\n",
    "$$\n",
    "d_{\\text{i_out}} = (d_{\\text{i_in}} - 1) \\times \\text{stride}_i - 2 \\times \\text{padding}_i + \\text{dilation}_i \\times (\\text{kernel_size}_i - 1) + \\text{output_padding}_i + 1\n",
    "$$\n",
    "\n",
    "Note that the equation for nn.ConvTranspose3d and nn.Conv3d are mathematically equal except $d_{\\text{i_in}}$ and $d_{\\text{i_out}}$ are swapped, and $\\text{output_padding}_i$ is added on at the end.\n",
    "\n",
    "$$\n",
    "d_{\\text{i_in}} = \\frac{d_{\\text{i_out}} + 2 \\times \\text{padding}_i - \\text{dilation}_i \\times (\\text{kernel_size}_i -1) - 1}{\\text{stride}_i} + 1\n",
    "$$\n",
    "$$\n",
    "(d_{\\text{i_in}} - 1) \\times \\text{stride}_i = d_{\\text{i_out}} + 2 \\times \\text{padding}_i - \\text{dilation}_i \\times (\\text{kernel_size}_i -1) - 1\n",
    "$$\n",
    "$$\n",
    "d_{\\text{i_out}} = (d_{\\text{i_in}} - 1) \\times \\text{stride}_i - 2 \\times \\text{padding}_i + \\text{dilation}_i \\times (\\text{kernel_size}_i -1) + (\\text{output_padding}_i) + 1\n",
    "$$"
   ],
   "id": "adbda1575b4cf66d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Again, $\\text{dilation}_i = 1$, and let $\\text{kernel_size}_i = k$, $\\text{stride} = s$, and as aforementioned $\\text{output_padding} = 0$ so we can simplify the equation to: \n",
    "$$\n",
    "d_{\\text{i_out}} = (d_{\\text{i_in}} - 1) \\times s - 2 \\times \\text{padding}_i + k\n",
    "$$\n",
    "\n",
    "Example: our compressed phi_bin dimension is 5, expected 10 after upsample with stride 2. We know $\\text{padding}_i = 3$ and $k = 4$. Our $d_\\text{i_in} = 7$ due to artificial padding of 1 on each side (5 + 1 + 1):\n",
    "$$\n",
    "10 = (7 - 1) \\times 2 - 2 \\times 3 + 4\n",
    "$$\n",
    "$$\n",
    "10 = 10\n",
    "$$"
   ],
   "id": "b1807edbb99072d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Again, $d_\\text{i_in} = d_i + p \\times 2$, and ideally $d_\\text{i_out} = d_i \\times s$, and so for our artificial padding $p$:\n",
    "$$\n",
    "d_i \\times s = (d_i + p \\times 2 - 1) \\times s - 2 \\times \\text{padding}_i + k\n",
    "$$\n",
    "$$\n",
    "d_i \\times s = d_i \\times s + (p \\times 2 - 1) \\times s - 2 \\times \\text{padding}_i + k\n",
    "$$\n",
    "$$\n",
    "2 \\times \\text{padding}_i - k = (p \\times 2 - 1) \\times s\n",
    "$$\n",
    "$$\n",
    "\\frac{2 \\times \\text{padding}_i - k}{s} = p \\times 2 - 1\n",
    "$$\n",
    "$$\n",
    "p = \\frac{\\frac{2 \\times \\text{padding}_i - k}{s} + 1}{2}\n",
    "$$"
   ],
   "id": "12508142e8d9118f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We take away the same issues here as we did from the downsampling, as p can only be an integer. Additionally, we need to ensure that the upsampled dimension matches the original input dimension across multiple operations. Seeing that $\\text{padding}_i$ is hardcoded to 3 for the phi_bin dimension again brings the question if we should modify addiional parameters beyond the artificial padding. A potential solution is just making $\\text{padding}_i = 0$ to mimic the downsample nn.Conv3d function, however we would still need to address the integer p issue.",
   "id": "974214f72580e58e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Look to Emily for using both ConvTranspose3d and Conv3d to achieve this?",
   "id": "3dedaa0630c6ab9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Compress factor of 2, layer sizes [16, 16, 16] (2 downsamples)  \n",
    "dim / dim_out refers to layer dimensions  \n",
    "1 downsample = ResnetBlock1 > ResnetBlock2 > Attention > Downsample (nn.Identity if last)\n",
    "1 Resnetblock = block1 > block2 > res_conv (CylindricalConv(dim, dim_out, kernel_size=1) only if dim change otherwise nn.Identity())  \n",
    "1 Attention = Residual(PreNorm(dim_out, LinearAttention(dim_out, cylindrical=cylindrical)  \n",
    "1 Linear Attention = to_qkv (CylindricalConv(dim, hidden_dim*3, kernel_size=1, bias=False) > to_out (Sequential(CylindricalConv(hidden_dim, dim, kernel_size=1) > GroupNorm)  \n",
    "1 block = proj (CylindricalConv(dim, dim_out, kernel_size=3, padding=1) > norm (GroupNorm) > activation (SiLu)  \n",
    "\n",
    "In this case:  \n",
    "block 1 > block 2 > nn.Identity  \n",
    "```\n",
    "Initial Conv: torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "DOWNSAMPLE RESNET BLOCK START\n",
    "\n",
    "ResnetBlock1\n",
    "    Block 1\n",
    "    CylindricalConv forward pad: torch.Size([128, 16, 5, 12, 30])\n",
    "    CylindricalConv internal conv: torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "    Block 2\n",
    "    CylindricalConv forward pad: torch.Size([128, 16, 5, 12, 30])\n",
    "    CylindricalConv internal conv: torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "    Identity\n",
    "    torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "ResnetBlock2\n",
    "    Block 1\n",
    "    CylindricalConv forward pad: torch.Size([128, 16, 5, 12, 30])\n",
    "    CylindricalConv internal conv: torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "    Block 2\n",
    "    CylindricalConv forward pad: torch.Size([128, 16, 5, 12, 30])\n",
    "    CylindricalConv internal conv: torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "    Identity\n",
    "    torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "Linear Attention\n",
    "    to_qkv    \n",
    "    CylindricalConv forward pad: torch.Size([128, 16, 5, 10, 30])\n",
    "    CylindricalConv internal conv: torch.Size([128, 96, 5, 10, 30])\n",
    "\n",
    "    to_out\n",
    "    CylindricalConv forward pad: torch.Size([128, 32, 5, 10, 30])\n",
    "    CylindricalConv internal conv: torch.Size([128, 16, 5, 10, 30])\n",
    "\n",
    "Downsample\n",
    "CylindricalConv forward pad: torch.Size([128, 16, 5, 12, 30])\n",
    "CylindricalConv internal conv: torch.Size([128, 16, 3, 5, 15])\n",
    "\n",
    "Result Downsample 1: torch.Size([128, 16, 3, 5, 15])\n",
    "```"
   ],
   "id": "b2012931ff88189b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
